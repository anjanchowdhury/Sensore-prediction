{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98572,"databundleVersionId":11761671,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T07:58:35.227249Z","iopub.execute_input":"2025-04-10T07:58:35.227923Z","iopub.status.idle":"2025-04-10T07:58:35.233954Z","shell.execute_reply.started":"2025-04-10T07:58:35.227897Z","shell.execute_reply":"2025-04-10T07:58:35.232919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom IPython.display import display\n\n# Load the data\ntrain_df = pd.read_parquet('/kaggle/input/celebal-ana-verse-j/train.parquet')\ntest_df = pd.read_parquet('/kaggle/input/celebal-ana-verse-j/test.parquet')\nsample_submission = pd.read_parquet('/kaggle/input/celebal-ana-verse-j/sample_submission.parquet')\n\n# Display all heads\nprint(\"Train Data:\")\ndisplay(train_df.head())\n\nprint(\"\\nTest Data:\")\ndisplay(test_df.head())\n\nprint(\"\\nSample Submission:\")\ndisplay(sample_submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:03:37.328283Z","iopub.execute_input":"2025-04-10T08:03:37.328618Z","iopub.status.idle":"2025-04-10T08:03:37.546333Z","shell.execute_reply.started":"2025-04-10T08:03:37.328595Z","shell.execute_reply":"2025-04-10T08:03:37.545487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train shape:\", train_df.shape)\nprint(\"Test shape:\", test_df.shape)\n\nprint(\"\\nTrain columns:\\n\", train_df.columns.tolist())\nprint(\"\\nMissing values in train:\\n\", train_df.isnull().sum())\n\nprint(\"\\nTarget distribution:\\n\", train_df['target'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:03:42.403588Z","iopub.execute_input":"2025-04-10T08:03:42.403923Z","iopub.status.idle":"2025-04-10T08:03:42.633853Z","shell.execute_reply.started":"2025-04-10T08:03:42.403900Z","shell.execute_reply":"2025-04-10T08:03:42.632870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.nunique())\nprint(train_df.describe())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:04:59.954718Z","iopub.execute_input":"2025-04-10T08:04:59.955020Z","iopub.status.idle":"2025-04-10T08:05:00.647037Z","shell.execute_reply.started":"2025-04-10T08:04:59.954997Z","shell.execute_reply":"2025-04-10T08:05:00.646089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Date'] = pd.to_datetime(train_df['Date'])\ntrain_df['Day'] = train_df['Date'].dt.day\ntrain_df['Month'] = train_df['Date'].dt.month\ntrain_df['Year'] = train_df['Date'].dt.year\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:05:15.318236Z","iopub.execute_input":"2025-04-10T08:05:15.319127Z","iopub.status.idle":"2025-04-10T08:05:15.513102Z","shell.execute_reply.started":"2025-04-10T08:05:15.319094Z","shell.execute_reply":"2025-04-10T08:05:15.511753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.countplot(data=train_df, x='target')\nplt.title(\"Target Class Distribution\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:05:35.197003Z","iopub.execute_input":"2025-04-10T08:05:35.197325Z","iopub.status.idle":"2025-04-10T08:05:37.497039Z","shell.execute_reply.started":"2025-04-10T08:05:35.197302Z","shell.execute_reply":"2025-04-10T08:05:37.495781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr = train_df.corr(numeric_only=True)\nplt.figure(figsize=(10,6))\nsns.heatmap(corr, annot=True, cmap='coolwarm')\nplt.title(\"Correlation Heatmap\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:05:55.229176Z","iopub.execute_input":"2025-04-10T08:05:55.229672Z","iopub.status.idle":"2025-04-10T08:05:56.022305Z","shell.execute_reply.started":"2025-04-10T08:05:55.229647Z","shell.execute_reply":"2025-04-10T08:05:56.021460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.boxplot(data=train_df, x='target', y='X1')\nplt.title('X1 vs Target')\nplt.show()\n\n# Repeat for other features like X2, X3, etc.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:06:06.146208Z","iopub.execute_input":"2025-04-10T08:06:06.146551Z","iopub.status.idle":"2025-04-10T08:06:07.097346Z","shell.execute_reply.started":"2025-04-10T08:06:06.146527Z","shell.execute_reply":"2025-04-10T08:06:07.096357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['DayOfWeek'] = train_df['Date'].dt.dayofweek\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:07:01.599364Z","iopub.execute_input":"2025-04-10T08:07:01.600196Z","iopub.status.idle":"2025-04-10T08:07:01.662771Z","shell.execute_reply.started":"2025-04-10T08:07:01.600171Z","shell.execute_reply":"2025-04-10T08:07:01.662013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['Date'] = pd.to_datetime(test_df['Date'])\ntest_df['Day'] = test_df['Date'].dt.day\ntest_df['Month'] = test_df['Date'].dt.month\ntest_df['Year'] = test_df['Date'].dt.year\ntest_df['DayOfWeek'] = test_df['Date'].dt.dayofweek\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:07:12.585244Z","iopub.execute_input":"2025-04-10T08:07:12.585642Z","iopub.status.idle":"2025-04-10T08:07:12.658272Z","shell.execute_reply.started":"2025-04-10T08:07:12.585618Z","shell.execute_reply":"2025-04-10T08:07:12.657376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['target'] = train_df['target'].astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:08:04.385248Z","iopub.execute_input":"2025-04-10T08:08:04.385907Z","iopub.status.idle":"2025-04-10T08:08:04.528766Z","shell.execute_reply.started":"2025-04-10T08:08:04.385881Z","shell.execute_reply":"2025-04-10T08:08:04.527656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_by_date = train_df.groupby('Date')['target'].mean()\ntarget_by_date.plot(figsize=(12,6), title=\"Daily Target Rate\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:08:11.933464Z","iopub.execute_input":"2025-04-10T08:08:11.934161Z","iopub.status.idle":"2025-04-10T08:08:12.420450Z","shell.execute_reply.started":"2025-04-10T08:08:11.934130Z","shell.execute_reply":"2025-04-10T08:08:12.419576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_by_date['2024-01':'2024-03'].plot(title=\"Target Rate (Jan-Mar 2024)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:08:55.506476Z","iopub.execute_input":"2025-04-10T08:08:55.506790Z","iopub.status.idle":"2025-04-10T08:08:55.795331Z","shell.execute_reply.started":"2025-04-10T08:08:55.506770Z","shell.execute_reply":"2025-04-10T08:08:55.794103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_by_date.rolling(window=7).mean().plot(figsize=(12,6), title=\"7-Day Rolling Average of Target Rate\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:09:02.934742Z","iopub.execute_input":"2025-04-10T08:09:02.935060Z","iopub.status.idle":"2025-04-10T08:09:03.268475Z","shell.execute_reply.started":"2025-04-10T08:09:02.935036Z","shell.execute_reply":"2025-04-10T08:09:03.267568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:10:01.830895Z","iopub.execute_input":"2025-04-10T08:10:01.831572Z","iopub.status.idle":"2025-04-10T08:10:01.836574Z","shell.execute_reply.started":"2025-04-10T08:10:01.831543Z","shell.execute_reply":"2025-04-10T08:10:01.835548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.groupby('X1')['target'].mean().sort_values().plot(kind='barh', figsize=(10,6), title=\"Average Target by X1\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:10:25.003168Z","iopub.execute_input":"2025-04-10T08:10:25.003555Z","iopub.status.idle":"2025-04-10T08:10:30.222479Z","shell.execute_reply.started":"2025-04-10T08:10:25.003531Z","shell.execute_reply":"2025-04-10T08:10:30.221484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Drop non-feature columns\nX = train_df.drop(columns=['Date', 'target'])\ny = train_df['target']\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:12:08.331973Z","iopub.execute_input":"2025-04-10T08:12:08.332316Z","iopub.status.idle":"2025-04-10T08:12:09.565241Z","shell.execute_reply.started":"2025-04-10T08:12:08.332281Z","shell.execute_reply":"2025-04-10T08:12:09.564554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Initialize with class weights\nrf = RandomForestClassifier(class_weight='balanced', random_state=42)\n\n# Train\nrf.fit(X_train, y_train)\n\n# Predict\ny_pred = rf.predict(X_test)\n\n# Evaluate\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:12:21.315727Z","iopub.execute_input":"2025-04-10T08:12:21.316046Z","iopub.status.idle":"2025-04-10T08:15:36.831167Z","shell.execute_reply.started":"2025-04-10T08:12:21.316025Z","shell.execute_reply":"2025-04-10T08:15:36.830305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Get feature importances from the trained model\nimportances = rf.feature_importances_\n\n# Create a DataFrame for better plotting\nfeat_imp_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': importances\n}).sort_values(by='Importance', ascending=False)\n\n# Plot\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=feat_imp_df)\nplt.title('Feature Importances from Random Forest')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:16:50.070124Z","iopub.execute_input":"2025-04-10T08:16:50.070461Z","iopub.status.idle":"2025-04-10T08:16:50.316605Z","shell.execute_reply.started":"2025-04-10T08:16:50.070438Z","shell.execute_reply":"2025-04-10T08:16:50.315476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# STEP 1: Copy test data\ntest_processed = test_df.copy()\n\n# STEP 2: Process 'Date' column to extract features like in training\ntest_processed['Date'] = pd.to_datetime(test_processed['Date'])\ntest_processed['Day'] = test_processed['Date'].dt.day\ntest_processed['Month'] = test_processed['Date'].dt.month\ntest_processed['Year'] = test_processed['Date'].dt.year\ntest_processed['DayOfWeek'] = test_processed['Date'].dt.dayofweek\n\n# STEP 3: Drop original 'Date' column\nX_final_test = test_processed.drop(['Date'], axis=1)\n\n# STEP 4: Drop 'ID' from features if model was trained without it\nX_final_test = X_final_test.drop('ID', axis=1)\n\n# STEP 5: Predict using trained RandomForest model\nfinal_predictions = rf.predict(X_final_test)\n\n# STEP 6: Prepare submission DataFrame\nsubmission_df = pd.DataFrame({\n    'ID': test_df['ID'],  # ID from original test data\n    'target': final_predictions\n})\n\n# STEP 7: Save to CSV\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:21:24.787618Z","iopub.execute_input":"2025-04-10T08:21:24.788480Z","iopub.status.idle":"2025-04-10T08:21:29.022780Z","shell.execute_reply.started":"2025-04-10T08:21:24.788444Z","shell.execute_reply":"2025-04-10T08:21:29.021726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install xgboost\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:28:24.628017Z","iopub.execute_input":"2025-04-10T08:28:24.628598Z","iopub.status.idle":"2025-04-10T08:28:30.857574Z","shell.execute_reply.started":"2025-04-10T08:28:24.628571Z","shell.execute_reply":"2025-04-10T08:28:30.855742Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:28:41.004029Z","iopub.execute_input":"2025-04-10T08:28:41.004459Z","iopub.status.idle":"2025-04-10T08:28:41.365807Z","shell.execute_reply.started":"2025-04-10T08:28:41.004367Z","shell.execute_reply":"2025-04-10T08:28:41.364865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate scale_pos_weight = (negative class / positive class)\nneg, pos = y_train.value_counts()\nscale_pos_weight = neg / pos\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:28:58.427123Z","iopub.execute_input":"2025-04-10T08:28:58.427481Z","iopub.status.idle":"2025-04-10T08:28:58.440807Z","shell.execute_reply.started":"2025-04-10T08:28:58.427457Z","shell.execute_reply":"2025-04-10T08:28:58.439708Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_clf = XGBClassifier(\n    objective='binary:logistic',\n    scale_pos_weight=scale_pos_weight,\n    eval_metric='logloss',\n    use_label_encoder=False,\n    random_state=42\n)\n\nxgb_clf.fit(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:29:09.935527Z","iopub.execute_input":"2025-04-10T08:29:09.935828Z","iopub.status.idle":"2025-04-10T08:29:15.749804Z","shell.execute_reply.started":"2025-04-10T08:29:09.935807Z","shell.execute_reply":"2025-04-10T08:29:15.748989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = xgb_clf.predict(X_test)\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:29:28.070243Z","iopub.execute_input":"2025-04-10T08:29:28.071010Z","iopub.status.idle":"2025-04-10T08:29:28.874362Z","shell.execute_reply.started":"2025-04-10T08:29:28.070979Z","shell.execute_reply":"2025-04-10T08:29:28.873342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# STEP 1: Copy test data\ntest_processed = test_df.copy()\n\n# STEP 2: Process 'Date' column to extract features like in training\ntest_processed['Date'] = pd.to_datetime(test_processed['Date'])\ntest_processed['Day'] = test_processed['Date'].dt.day\ntest_processed['Month'] = test_processed['Date'].dt.month\ntest_processed['Year'] = test_processed['Date'].dt.year\ntest_processed['DayOfWeek'] = test_processed['Date'].dt.dayofweek\n\n# STEP 3: Drop original 'Date' column\nX_final_test = test_processed.drop(['Date'], axis=1)\n\n# STEP 4: Drop 'ID' from features if model was trained without it\nX_final_test = X_final_test.drop('ID', axis=1)\n\nfinal_predictions = xgb_clf.predict(X_final_test)\n# STEP 6: Prepare submission DataFrame\nsubmission_df = pd.DataFrame({\n    'ID': test_df['ID'],  # ID from original test data\n    'target': final_predictions\n})\n\n# STEP 7: Save to CSV\n# Save to CSV\nsubmission_df.to_csv('xgb_submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T08:32:06.621617Z","iopub.execute_input":"2025-04-10T08:32:06.621947Z","iopub.status.idle":"2025-04-10T08:32:07.615781Z","shell.execute_reply.started":"2025-04-10T08:32:06.621929Z","shell.execute_reply":"2025-04-10T08:32:07.614993Z"}},"outputs":[],"execution_count":null}]}